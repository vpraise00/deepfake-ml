{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9c6105",
   "metadata": {},
   "source": [
    "# FFPP Deepfake Detection Pipeline (K-Fold + Test 포함)\n",
    "\n",
    "이 노트북은 `deepfake_adapter_ffpp` 프로젝트의 전체 파이프라인을 **세 단계**로 통합합니다:\n",
    "\n",
    "1. **데이터 로드 및 전처리**  \n",
    "   - `configs/ffpp_c23.yaml`을 기반으로 데이터 경로 설정  \n",
    "   - `FFPPFrameDataset`을 사용해 “train+val”을 병합하여 로드  \n",
    "   - `src/utils/transforms.py`의 전처리(transform) 함수 확인  \n",
    "\n",
    "2. **모델 학습 + 검증 (5-Fold Cross-Validation)**  \n",
    "   - `DeepfakeAdapter` 모델을 매 Fold마다 초기화  \n",
    "   - 각 Fold마다 Train/Val로 분할하여,  \n",
    "     - Epoch별 **Training Loss**를 기록하고,  \n",
    "     - Epoch별 **Validation AUC/EER**를 계산하여 TensorBoard에 기록  \n",
    "   - 각 Fold의 **최적 모델(best.pth)**을 `outputs/checkpoints/ffpp_c23/fold_{i}/best.pth`에 저장  \n",
    "\n",
    "3. **모델 평가 (Test)**  \n",
    "   - 마지막 Fold의 최적 모델을 불러와  \n",
    "   - `FFPPFrameDataset(split=\"test\")`으로 Test Loader 구성  \n",
    "   - **Test AUC/EER**를 계산  \n",
    "\n",
    "4. **모델 추론 (Inference)**  \n",
    "   - Test 평가 이후, 새로운 **단일 비디오**를 “영상→프레임→예측” 과정을 거쳐  \n",
    "   - `outputs/predictions/[video_name].json`으로 프레임별 Deepfake 확률 저장  \n",
    "   - (선택) 상위 확률 프레임 시각화  \n",
    "\n",
    "---\n",
    "\n",
    "노트북을 실행하기 전에, 다음 사항을 확인하세요:\n",
    "\n",
    "- `deepfake_adapter_ffpp/` 디렉터리가 아래와 같이 구성되어 있어야 합니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819d221",
   "metadata": {},
   "source": [
    "- `configs/ffpp_c23.yaml`의 `dataset_root` 경로를 본인 환경에 맞게 수정하세요.  \n",
    "- 필요한 라이브러리(`torch`, `timm`, `yaml`, `opencv-python`, `torchvision`, `sklearn` 등)를 설치합니다:  \n",
    "```bash\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 2: 라이브러리 임포트 및 설정 불러오기\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# src/ 경로를 import 경로에 추가\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# 사용자 정의 모듈\n",
    "from src.datasets.ffpp_dataset import FFPPFrameDataset\n",
    "from src.models.deepfake_adapter import DeepfakeAdapter\n",
    "from src.utils.transforms import get_ffpp_transforms\n",
    "from src.utils.metrics import compute_auc, compute_eer\n",
    "\n",
    "# --- 설정(Config) 로드 ---\n",
    "config_path = \"configs/ffpp_c23.yaml\"  # 필요 시 \"configs/ffpp_c40.yaml\" 선택\n",
    "with open(config_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# 재현성(Seed) 고정 함수\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 우선)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"Config:\", cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d0ad6",
   "metadata": {},
   "source": [
    "## 데이터셋 로드 및 전처리 확인\n",
    "\n",
    "- `FFPPFrameDataset(split=\"trainval\")`을 이용해 **Train+Val** 데이터셋을 한 번에 로드합니다.\n",
    "- `get_ffpp_transforms(cfg[\"input_size\"])`으로 이미지가 Resize→ToTensor→Normalize 되어 로드되는지 확인합니다.\n",
    "- 샘플 이미지를 시각화하여 전처리 결과를 눈으로 확인해 봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 3: 데이터셋 로드 및 전처리 확인\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 1) Train+Val 데이터셋 로드\n",
    "full_dataset = FFPPFrameDataset(config_path, split=\"trainval\")\n",
    "print(f\"Total Train+Val samples: {len(full_dataset)}\")\n",
    "\n",
    "# 2) DataLoader(임시) — K-Fold 전에 batch 확인용\n",
    "temp_loader = DataLoader(\n",
    "    full_dataset,\n",
    "    batch_size=cfg[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=cfg[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# 3) 첫 번째 배치 가져와서 이미지 텐서 모양 확인\n",
    "images, labels = next(iter(temp_loader))\n",
    "print(\"Batch images shape:\", images.shape)  # [batch_size, 3, input_size, input_size]\n",
    "print(\"Batch labels shape:\", labels.shape)  # [batch_size]\n",
    "\n",
    "# 4) 샘플 이미지 시각화 (정규화 해제 후 표시)\n",
    "def imshow_tensor(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    \"\"\"정규화된 텐서를 이미지로 되돌려 Matplotlib으로 표시\"\"\"\n",
    "    img = img_tensor.clone().cpu().numpy()\n",
    "    for c in range(3):\n",
    "        img[c] = img[c] * std[c] + mean[c]\n",
    "    img = np.clip(img, 0, 1)\n",
    "    img = np.transpose(img, (1, 2, 0))  # (H, W, C)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "for i in range(4):\n",
    "    imshow_tensor(images[i])\n",
    "    axes[i].set_title(f\"Label: {labels[i].item()}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b67aab1",
   "metadata": {},
   "source": [
    "## 학습(Training) + 검증(Validation) + Test 평가\n",
    "\n",
    "- `DeepfakeAdapter` 모델을 **5-Fold**로 cross-validation 합니다:\n",
    "  1. **Train+Val 전체 데이터**(`split=\"trainval\"`)를 로드  \n",
    "  2. `sklearn.model_selection.KFold`로 **K=5** 개의 fold 분할  \n",
    "     - `train_idx`, `val_idx`를 사용해 각각 `Subset`으로 DataLoader 구성  \n",
    "     - Fold마다 모델을 학습하고 Validation AUC/EER 계산 후, **Fold별 최적 모델** 저장  \n",
    "  3. **마지막(Fold 5) 모델**을 로드하여 Test 데이터셋(`split=\"test\"`)에 대해 **최종 성능(Test AUC/EER)** 계산  \n",
    "\n",
    "- TensorBoard 로그:  \n",
    "  - `outputs/logs/ffpp_c23/fold_i` 폴더에서 확인 가능  \n",
    "- Checkpoint 저장:  \n",
    "  - `outputs/checkpoints/ffpp_c23/fold_i/best.pth` 형태로 저장  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 4: 학습 + 검증 + Test 평가 (5-Fold CV)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 1) Train+Val 데이터셋 로드\n",
    "full_dataset = FFPPFrameDataset(config_path, split=\"trainval\")\n",
    "num_samples = len(full_dataset)\n",
    "print(f\"Total Train+Val samples: {num_samples}\")\n",
    "\n",
    "# 2) K-Fold 분할 준비\n",
    "k_folds = cfg[\"training\"].get(\"k_folds\", 5)\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# 3) Fold별 학습/검증\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(range(num_samples))):\n",
    "    print(f\"\\n--- Fold {fold+1}/{k_folds} ---\")\n",
    "    # Train/Val Subset 구성\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset   = Subset(full_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=cfg[\"num_workers\"],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=cfg[\"num_workers\"],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # (A) 모델/옵티/스케줄러/손실함수 정의\n",
    "    model = DeepfakeAdapter(cfg).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg[\"optimizer\"][\"lr\"],\n",
    "        weight_decay=cfg[\"optimizer\"][\"weight_decay\"]\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=cfg[\"scheduler\"][\"T_max\"]\n",
    "    )\n",
    "\n",
    "    # (B) Fold별 체크포인트/로그 디렉터리\n",
    "    fold_ckpt_dir = os.path.join(cfg[\"output_dir\"], f\"fold_{fold+1}\")\n",
    "    fold_log_dir  = os.path.join(cfg[\"log_dir\"], f\"fold_{fold+1}\")\n",
    "    os.makedirs(fold_ckpt_dir, exist_ok=True)\n",
    "    os.makedirs(fold_log_dir, exist_ok=True)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=fold_log_dir)\n",
    "    best_auc = 0.0\n",
    "\n",
    "    # (C) Epoch별 학습 + 검증 루프\n",
    "    for epoch in range(cfg[\"training\"][\"epochs\"]):\n",
    "        #########################\n",
    "        # (C-1) Training 단계\n",
    "        #########################\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
    "\n",
    "        #########################\n",
    "        # (C-2) Validation 단계\n",
    "        #########################\n",
    "        model.eval()\n",
    "        all_labels = []\n",
    "        all_scores = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                logits = model(images)\n",
    "                probs = torch.softmax(logits, dim=1)[:, 1]  # fake 확률\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_scores.extend(probs.cpu().numpy())\n",
    "\n",
    "        val_auc = compute_auc(np.array(all_labels), np.array(all_scores))\n",
    "        val_eer = compute_eer(np.array(all_labels), np.array(all_scores))\n",
    "        writer.add_scalar(\"AUC/val\", val_auc, epoch)\n",
    "        writer.add_scalar(\"EER/val\", val_eer, epoch)\n",
    "\n",
    "        print(\n",
    "            f\"[Fold {fold+1}/{k_folds} | Epoch {epoch+1}/{cfg['training']['epochs']}] \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f}  Val AUC: {val_auc:.4f}  Val EER: {val_eer:.4f}\"\n",
    "        )\n",
    "\n",
    "        #########################\n",
    "        # (C-3) 최적 모델 저장\n",
    "        #########################\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            ckpt = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"auc\": val_auc,\n",
    "            }\n",
    "            save_path = os.path.join(fold_ckpt_dir, \"best.pth\")\n",
    "            torch.save(ckpt, save_path)\n",
    "            print(f\"→ New best model for Fold {fold+1} saved at {save_path}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "# 4) 5-Fold 완료 후 Test 셋 평가\n",
    "print(\"\\n=== K-Fold Training Complete ===\")\n",
    "print(\"Evaluating on the Test set using Fold 5's best model...\")\n",
    "\n",
    "# (D) Test Dataset/Loader\n",
    "test_dataset = FFPPFrameDataset(config_path, split=\"test\")\n",
    "test_loader  = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=cfg[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# (E) Fold 5 최적 모델 로드\n",
    "last_ckpt_path = os.path.join(cfg[\"output_dir\"], f\"fold_{k_folds}\", \"best.pth\")\n",
    "assert os.path.exists(last_ckpt_path), f\"Checkpoint not found: {last_ckpt_path}\"\n",
    "\n",
    "model = DeepfakeAdapter(cfg).to(device)\n",
    "ckpt = torch.load(last_ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# (F) Test 셋 예측 및 지표 출력\n",
    "all_test_labels = []\n",
    "all_test_scores = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(images)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]  # fake 확률\n",
    "\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_scores.extend(probs.cpu().numpy())\n",
    "\n",
    "test_auc = compute_auc(np.array(all_test_labels), np.array(all_test_scores))\n",
    "test_eer = compute_eer(np.array(all_test_labels), np.array(all_test_scores))\n",
    "print(f\"Final Test AUC: {test_auc:.4f}\")\n",
    "print(f\"Final Test EER: {test_eer:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16421d86",
   "metadata": {},
   "source": [
    "## 추론(Inference)\n",
    "\n",
    "- 학습된 Test 모델(`fold_5/best.pth`)을 사용하여 **단일 비디오**에 대해 Deepfake 확률을 예측하고,  \n",
    "  결과를 프레임 단위 JSON 파일(`outputs/predictions/[video_name].json`)로 저장합니다.\n",
    "- 과정:\n",
    "  1. `cv2.VideoCapture`로 비디오를 열어 `temp_frames_infer/` 폴더에 프레임 저장  \n",
    "  2. 저장된 프레임에 대해 `get_ffpp_transforms(cfg[\"input_size\"])` 적용 후 모델 예측  \n",
    "  3. 각 프레임별 fake 확률을 JSON으로 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc884d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 5: 추론(Inference)\n",
    "\n",
    "# (A) 추론할 비디오 파일 경로 지정 (본인이 테스트할 비디오 경로로 수정)\n",
    "test_video_path = \"data/raw_videos/sample_video.mp4\"  # 예시\n",
    "assert os.path.exists(test_video_path), f\"Video not found: {test_video_path}\"\n",
    "\n",
    "# (B) 임시 폴더에 프레임 추출\n",
    "temp_frames_dir = \"temp_frames_infer\"\n",
    "if os.path.exists(temp_frames_dir):\n",
    "    for f in os.listdir(temp_frames_dir):\n",
    "        os.remove(os.path.join(temp_frames_dir, f))\n",
    "else:\n",
    "    os.makedirs(temp_frames_dir)\n",
    "\n",
    "cap = cv2.VideoCapture(test_video_path)\n",
    "frame_idx = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    save_path = os.path.join(temp_frames_dir, f\"frame_{frame_idx:06d}.jpg\")\n",
    "    cv2.imwrite(save_path, frame)\n",
    "    frame_idx += 1\n",
    "cap.release()\n",
    "print(f\"Extracted {frame_idx} frames to '{temp_frames_dir}'\")\n",
    "\n",
    "# (C) TempFrameDataset 정의 및 DataLoader 구성\n",
    "transform = get_ffpp_transforms(cfg[\"input_size\"])\n",
    "frame_paths = sorted([\n",
    "    os.path.join(temp_frames_dir, fn)\n",
    "    for fn in os.listdir(temp_frames_dir)\n",
    "    if fn.endswith(\".jpg\") or fn.endswith(\".png\")\n",
    "])\n",
    "\n",
    "class TempFrameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, transform):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        return self.transform(img), self.paths[idx]\n",
    "\n",
    "temp_dataset = TempFrameDataset(frame_paths, transform)\n",
    "temp_loader = DataLoader(\n",
    "    temp_dataset,\n",
    "    batch_size=cfg[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=cfg[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# (D) 마지막 Fold 모델 로드\n",
    "best_ckpt_path = os.path.join(cfg[\"output_dir\"], f\"fold_{cfg['training']['k_folds']}\", \"best.pth\")\n",
    "assert os.path.exists(best_ckpt_path), f\"Checkpoint not found: {best_ckpt_path}\"\n",
    "\n",
    "model = DeepfakeAdapter(cfg).to(device)\n",
    "ckpt = torch.load(best_ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# (E) 프레임 단위 예측\n",
    "results = {}  # { \"frame_path\": fake_probability }\n",
    "with torch.no_grad():\n",
    "    for imgs, paths in temp_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = model(imgs)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # fake 확률\n",
    "        for p, prob in zip(paths, probs):\n",
    "            results[p] = float(prob)\n",
    "\n",
    "# (F) JSON으로 저장\n",
    "video_name = os.path.splitext(os.path.basename(test_video_path))[0]\n",
    "output_json_dir = \"outputs/predictions\"\n",
    "os.makedirs(output_json_dir, exist_ok=True)\n",
    "output_json_path = os.path.join(output_json_dir, f\"{video_name}.json\")\n",
    "\n",
    "with open(output_json_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved prediction results to '{output_json_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00544d",
   "metadata": {},
   "source": [
    "## 결과 시각화 예시\n",
    "\n",
    "- **추출된 프레임 중 상위 5개**를 선택하여,  \n",
    "  프레임 원본 이미지 + 예측된 “Fake 확률”을 함께 시각화해 봅니다.\n",
    "- JSON 파일에서 상위 5개 확률 프레임을 골라서 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4254dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 6: 결과 시각화 예시\n",
    "\n",
    "with open(output_json_path, \"r\") as f:\n",
    "    results_json = json.load(f)\n",
    "\n",
    "# 프레임별 확률 내림차순 정렬 → 상위 5개\n",
    "sorted_items = sorted(results_json.items(), key=lambda x: x[1], reverse=True)\n",
    "top5 = sorted_items[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, (frame_path, prob) in enumerate(top5):\n",
    "    img = Image.open(frame_path).convert(\"RGB\")\n",
    "    axes[i].imshow(np.array(img))\n",
    "    axes[i].set_title(f\"{os.path.basename(frame_path)}\\nFake: {prob:.3f}\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bd3cc",
   "metadata": {},
   "source": [
    "## 마무리 및 토의\n",
    "\n",
    "1. **데이터 로드 및 전처리**  \n",
    "   - `split=\"trainval\"`로 **Train+Val** 전체를 K-Fold를 위해 하나의 데이터셋으로 로드하여,  \n",
    "     `get_ffpp_transforms`로 “Resize → ToTensor → Normalize”가 잘 적용되는 것을 확인했습니다.\n",
    "\n",
    "2. **5-Fold Cross-Validation 학습 + 검증**  \n",
    "   - `KFold(n_splits=5, shuffle=True, random_state=42)`를 사용해 **5개의 Fold**로 분할했으며,  \n",
    "   - 각 Fold마다 학습 및 검증을 반복하여 **Fold별 최적 모델**을 저장했습니다.  \n",
    "   - Fold별 Validation AUC/EER를 모니터링하며, TensorBoard에서 `outputs/logs/ffpp_c23/fold_i`를 확인 가능합니다.\n",
    "\n",
    "3. **Test 평가**  \n",
    "   - 5-Fold 학습을 마치고, **마지막(5번째) Fold의 최적 모델**을 로드하여 Test 데이터셋(`split=\"test\"`)에 대해 최종 AUC/EER를 계산했습니다.\n",
    "\n",
    "4. **추론(Inference)**  \n",
    "   - 새로운 비디오 파일을 “영상 → 프레임”으로 분할한 뒤,  \n",
    "   - 마지막 Fold 모델로 프레임별 Deepfake 확률을 예측하여 JSON(`outputs/predictions/[video_name].json`)에 저장했습니다.  \n",
    "\n",
    "5. **결과 시각화**  \n",
    "   - 상위 5개 “Fake 확률이 높은 프레임”을 화면에 출력하여,  \n",
    "     모델이 어느 순간 가장 Fake이라고 판단했는지 확인했습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 향후 방향\n",
    "\n",
    "- **Hyperparameter Tuning**:  \n",
    "  - `training.k_folds`, `optimizer.lr`, `scheduler.T_max`, `model.adapter_dim` 등을 변경해 가며 성능 최적화  \n",
    "  - Fold별로 저장된 체크포인트를 모아서 “Ensemble” 또는 “평균화(Averaging)” 기법 적용 가능\n",
    "\n",
    "- **Transformer-XAI**:  \n",
    "  - 현재는 ViT + Dual-Level Adapter 기반 분류기까지만 구현되어 있습니다.  \n",
    "  - 추후 “Attention Map”, “Token Attribution” 등 Transformer 설명 기법을 추가하여,  \n",
    "    모델의 의사결정 근거를 시각화할 예정입니다.\n",
    "\n",
    "- **배포 및 서비스**:  \n",
    "  학습된 모델(`fold_{i}/best.pth`)을 REST API 또는 Streamlit 앱으로 배포하여,  \n",
    "  사용자가 업로드한 동영상에 대해 실시간으로 Deepfake 여부를 확인할 수 있도록 서비스화할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "이 노트북이 FFPP 기반 DeepFake Detection 전체 파이프라인을 이해하고, 직접 실험해보는 데 도움이 되길 바랍니다. 감사합니다!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
