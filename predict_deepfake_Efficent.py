import torch
import torchvision.transforms as transforms
from PIL import Image
import os
import json
from tqdm import tqdm
import sys

# âœ… Dummy ëª¨ë“ˆ ëŒ€ì²´ í´ë˜ìŠ¤ (timm.layers ì „ì²´ë¥¼ ëŒ€ì²´)
class DummyModule:
    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, x):
        return x  # ì…ë ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜

# âœ… "timm.layers"ì™€ í•˜ìœ„ ëª¨ë“ˆê¹Œì§€ ëª¨ë‘ Dummyë¡œ ëŒ€ì²´
sys.modules['timm.layers'] = DummyModule()
sys.modules['timm.layers.norm_act'] = DummyModule()  # âœ… ì¶”ê°€ëœ ë¶€ë¶„

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
MODEL_PATH = "model/CelebDF_8epoch.pt"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

try:
    checkpoint = torch.load(MODEL_PATH, map_location=device)
    model = checkpoint['model']
    model.load_state_dict(checkpoint['model_state_dict'])
except ModuleNotFoundError as e:
    print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    model = None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëª¨ë¸ì´ Noneìœ¼ë¡œ ì´ˆê¸°í™”

# âœ… ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
if model:
    model = model.to(device, memory_format=torch.channels_last)
    model.eval()

    # âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])

    def load_images_in_batches(image_paths, batch_size=16):
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i: i + batch_size]
            images = [transform(Image.open(img_path).convert("RGB")) for img_path in batch_paths]
            yield torch.stack(images).to(device), batch_paths

    def predict(images_tensor):
        with torch.no_grad():
            outputs = model(images_tensor)
            probabilities = torch.sigmoid(outputs).cpu().numpy()
        return probabilities

    def process_all_frames(input_folder, output_file, batch_size=16):
        image_files = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(".jpg")])
        if not image_files:
            print("âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        results = {}
        for batch_images, batch_paths in tqdm(load_images_in_batches(image_files, batch_size), total=len(image_files) // batch_size + 1, desc="ğŸ” Processing"):
            probs = predict(batch_images)
            for path, prob in zip(batch_paths, probs):
                frame_name = os.path.basename(path)
                results[frame_name] = float(prob)

        with open(output_file, "w") as f:
            json.dump(results, f, indent=4)
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")

    # âœ… ì‹¤í–‰ ì˜ˆì‹œ
    if __name__ == "__main__":
        import argparse

        parser = argparse.ArgumentParser(description="ë”¥í˜ì´í¬ í”„ë ˆì„ ë¶„ì„ê¸° (CelebDF_8epoch ëª¨ë¸)")
        parser.add_argument("--input", type=str, required=True, help="í”„ë ˆì„ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ")
        parser.add_argument("--output", type=str, default="results/deepfake_results_8epoch.json", help="ê²°ê³¼ ì €ì¥ íŒŒì¼")
        parser.add_argument("--batch_size", type=int, default=16, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 16)")

        args = parser.parse_args()
        process_all_frames(args.input, args.output, args.batch_size)
else:
    print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: timm.layers ê´€ë ¨ ì˜¤ë¥˜ë¡œ ì¸í•´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
